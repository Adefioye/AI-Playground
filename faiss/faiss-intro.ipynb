{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c0e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9fc2d",
   "metadata": {},
   "source": [
    "## Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66904d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pair_ID\\tsentence_A\\tsentence_B\\trelatedness_score\\tentailment_judgment\\n1\\tA group of kids is playing in '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "\n",
    "text = res.text\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7efcc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(StringIO(text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac44924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A group of kids is playing in a yard and an old man is standing in the background',\n",
       "  'A group of children is playing in the house and there is no man standing in the background',\n",
       "  'The young boys are playing outdoors and the man is smiling nearby',\n",
       "  'The kids are playing outdoors near a man with a smile',\n",
       "  'The young boys are playing outdoors and the man is smiling nearby'],\n",
       " 4500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5], len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8b4be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 4500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)\n",
    "len(set(sentences)), len(sentence_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f416d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa61c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e11b3463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810968cb",
   "metadata": {},
   "source": [
    "Before converting to our sentence embeddings, we will save to text file as backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558829d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates and NaN\n",
    "sentences = [\n",
    "    sentence.replace('\\n', '') for sentence in list(set(sentences)) if type(sentence) is str\n",
    "    ]\n",
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e81267",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d0f63",
   "metadata": {},
   "source": [
    "Now we have 14.5K unique sentences, a much better size. We'll go ahead and build the sentence embeddings (this can take some time, feel free to download the embeddings from here). TODO add link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3009b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-playground/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62836f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sim_sentences/embeddings_X.npy', 'wb') as fp:\n",
    "    np.save(fp, sentence_embeddings[0:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013733db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_0.npy | 0 -> 256\n",
      "embeddings_1.npy | 256 -> 512\n",
      "embeddings_2.npy | 512 -> 768\n",
      "embeddings_3.npy | 768 -> 1024\n",
      "embeddings_4.npy | 1024 -> 1280\n",
      "embeddings_5.npy | 1280 -> 1536\n",
      "embeddings_6.npy | 1536 -> 1792\n",
      "embeddings_7.npy | 1792 -> 2048\n",
      "embeddings_8.npy | 2048 -> 2304\n",
      "embeddings_9.npy | 2304 -> 2560\n",
      "embeddings_10.npy | 2560 -> 2816\n",
      "embeddings_11.npy | 2816 -> 3072\n",
      "embeddings_12.npy | 3072 -> 3328\n",
      "embeddings_13.npy | 3328 -> 3584\n",
      "embeddings_14.npy | 3584 -> 3840\n",
      "embeddings_15.npy | 3840 -> 4096\n",
      "embeddings_16.npy | 4096 -> 4352\n",
      "embeddings_17.npy | 4352 -> 4608\n",
      "embeddings_18.npy | 4608 -> 4864\n",
      "embeddings_19.npy | 4864 -> 5120\n",
      "embeddings_20.npy | 5120 -> 5376\n",
      "embeddings_21.npy | 5376 -> 5632\n",
      "embeddings_22.npy | 5632 -> 5888\n",
      "embeddings_23.npy | 5888 -> 6144\n",
      "embeddings_24.npy | 6144 -> 6400\n",
      "embeddings_25.npy | 6400 -> 6656\n",
      "embeddings_26.npy | 6656 -> 6912\n",
      "embeddings_27.npy | 6912 -> 7168\n",
      "embeddings_28.npy | 7168 -> 7424\n",
      "embeddings_29.npy | 7424 -> 7680\n",
      "embeddings_30.npy | 7680 -> 7936\n",
      "embeddings_31.npy | 7936 -> 8192\n",
      "embeddings_32.npy | 8192 -> 8448\n",
      "embeddings_33.npy | 8448 -> 8704\n",
      "embeddings_34.npy | 8704 -> 8960\n",
      "embeddings_35.npy | 8960 -> 9216\n",
      "embeddings_36.npy | 9216 -> 9472\n",
      "embeddings_37.npy | 9472 -> 9728\n",
      "embeddings_38.npy | 9728 -> 9984\n",
      "embeddings_39.npy | 9984 -> 10240\n",
      "embeddings_40.npy | 10240 -> 10496\n",
      "embeddings_41.npy | 10496 -> 10752\n",
      "embeddings_42.npy | 10752 -> 11008\n",
      "embeddings_43.npy | 11008 -> 11264\n",
      "embeddings_44.npy | 11264 -> 11520\n",
      "embeddings_45.npy | 11520 -> 11776\n",
      "embeddings_46.npy | 11776 -> 12032\n",
      "embeddings_47.npy | 12032 -> 12288\n",
      "embeddings_48.npy | 12288 -> 12544\n",
      "embeddings_49.npy | 12544 -> 12800\n",
      "embeddings_50.npy | 12800 -> 13056\n",
      "embeddings_51.npy | 13056 -> 13312\n",
      "embeddings_52.npy | 13312 -> 13568\n",
      "embeddings_53.npy | 13568 -> 13824\n",
      "embeddings_54.npy | 13824 -> 14080\n",
      "embeddings_55.npy | 14080 -> 14336\n",
      "embeddings_56.npy | 14336 -> 14505\n"
     ]
    }
   ],
   "source": [
    "# saving data\n",
    "split = 256\n",
    "file_count = 0\n",
    "for i in range(0, sentence_embeddings.shape[0], split):\n",
    "    end = i + split\n",
    "    if end > sentence_embeddings.shape[0] + 1:\n",
    "        end = sentence_embeddings.shape[0] + 1\n",
    "    file_count = '0' + str(file_count) if file_count < 0 else str(file_count)\n",
    "    with open(f'./sim_sentences/embeddings_{file_count}.npy', 'wb') as fp:\n",
    "        np.save(fp, sentence_embeddings[i:end, :])\n",
    "    print(f\"embeddings_{file_count}.npy | {i} -> {end}\")\n",
    "    file_count = int(file_count) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69624903",
   "metadata": {},
   "source": [
    "We setup our FAISS database dimensionality (number of dimensions per vector) based on these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e744257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e03c5",
   "metadata": {},
   "source": [
    "## Flat L2 Index\n",
    "We initialize the flat L2 distance index IndexFlatL2, all we need is the specify the vector dimensionality - which in this case is d == 768 (to align with the sentence-BERT model output embeddings of size 768)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f49163",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ac8b1",
   "metadata": {},
   "source": [
    "Often, we will use indexes that require us to train them on our data before being used (if we are grouping or transforming the data in any way). IndexFlatL2 however, is a simple operation and only requires that we calculate distances between vectors when we introduce our query vector xq during search. So, in this case, no training is required - which we can confirm by checking the is_trained attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a008cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c38a8",
   "metadata": {},
   "source": [
    "Okay so once we're happy that our index is prepared, we then add new vectors using the add method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a1d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4df1f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42f038",
   "metadata": {},
   "source": [
    "Then search given a query xq and number of nearest neigbors to return k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1974dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d77174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7090 2963 7946 7810]]\n",
      "CPU times: user 2.93 ms, sys: 2.89 ms, total: 5.82 ms\n",
      "Wall time: 5.06 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)  # k-nearest neigbors of the query vector | nprobe == 1: 6495 26392 61709 49932 | nprobe == 10: 36245  6495 57489  8705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a52acf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7090: A group of football players is running in the field',\n",
       " '2963: A group of people playing football is running in the field',\n",
       " '7946: Two groups of people are playing football',\n",
       " '7810: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6948ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A group of football players is running in the field'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[7090]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f15768",
   "metadata": {},
   "source": [
    "Clearly we have some good matches, everything returned includes people running with a football, or on the context of a football match. Now, if we'd rather extract the numerical vectors from FAISS, we can do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27b753e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.zeros((k, d))\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ec118c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b9e2e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627056,  0.22325902, -0.15037405, -0.30747285, -0.27122435,\n",
       "       -0.1059322 , -0.06460907,  0.04738186, -0.73349047, -0.37657705,\n",
       "       -0.76762813,  0.16902864,  0.53107703,  0.51176685,  1.14415872,\n",
       "       -0.08562887, -0.67240077, -0.9663704 ,  0.02545477, -0.2155983 ,\n",
       "       -1.25656593, -0.82982141, -0.09825017, -0.21850841,  0.5061022 ,\n",
       "        0.10527914,  0.50396866,  0.65242904, -1.39458704,  0.65847462,\n",
       "       -0.21525347, -0.22487469,  0.81818348,  0.08464274, -0.76141673,\n",
       "       -0.28928289, -0.09825772, -0.73046225,  0.07855783, -0.84354621,\n",
       "       -0.59242058,  0.77471304, -1.20920527, -0.22757967, -1.30733633,\n",
       "       -0.23081465, -1.31322539,  0.01629083, -0.97285444,  0.19308178,\n",
       "        0.47424588,  1.18920887, -1.96741331, -0.70061111, -0.29638639,\n",
       "        0.60533714,  0.62407392, -0.70340365, -0.86754227,  0.17673175,\n",
       "       -0.19170491, -0.02951992,  0.22623569, -0.16695412, -0.80402535,\n",
       "       -0.45918909,  0.69675493, -0.24928212, -1.01478708, -0.9217456 ,\n",
       "       -0.33842635, -0.39296818, -0.83734822, -0.11479244,  0.46049681,\n",
       "       -1.45211184,  0.60310417,  0.38696298, -0.04061221,  0.00453187,\n",
       "        0.24117815,  0.05396239,  0.07506445,  1.05115891,  0.12383952,\n",
       "       -0.71281099,  0.11722931,  0.52238154, -0.04581202,  0.26827094,\n",
       "        0.85985345, -0.35669944, -0.64667046, -0.54357988, -0.04310478,\n",
       "        0.95139152, -0.15605803, -0.49625286, -0.11140249,  0.15610142])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebece3",
   "metadata": {},
   "source": [
    "\n",
    "## Adding Partitioning to the Index\n",
    "FAISS allows us to add an additional step to optimize our search efficiency using a variety of different methods. A popular approach is to partition the index into Voronoi cells. Using this method we would take our query vector xq, identify the cell it belongs to, and then use our IndexFlatL2 to search between the query vector xq and all indexed vectors belonging to that cell. We can also include vectors from other nearby cells too.\n",
    "\n",
    "We initialize our new partitioned index by first adding our previous IndexFlatL2 operation as a quantization step (another step in the search process), and feeding this into the new IndexIVFFlat operation like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec9bb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 50\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abfc09",
   "metadata": {},
   "source": [
    "Here we've added a new parameter nlist. We use nlist to define how many partitions we'd like our index to have.\n",
    "\n",
    "When we built the previous, IndexFlatL2-only index, we noted that no training was required as no grouping/transformation was required to build that index. Now that we've added partitioning using IndexIVFFlat, this is no longer the case. Let's take a look at the is_trained attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f71270bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3fb5cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2ac7c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57211b8a",
   "metadata": {},
   "source": [
    "Let's search again using the same indexed sentence embeddings and the same query xq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c862f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2963 7946 7810 5174]]\n",
      "CPU times: user 365 μs, sys: 134 μs, total: 499 μs\n",
      "Wall time: 447 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807e73a",
   "metadata": {},
   "source": [
    "We can increase the number of nearby cells to search too with nprobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8329dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 10  # increase the number of nearby cells to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c219249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7090 2963 7946 7810]]\n",
      "CPU times: user 1.35 ms, sys: 1.41 ms, total: 2.76 ms\n",
      "Wall time: 1.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdba049",
   "metadata": {},
   "source": [
    "Rerunning can change the time to to the search. Let's do the search again and confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce333eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7090 2963 7946 7810]]\n",
      "CPU times: user 1.15 ms, sys: 791 μs, total: 1.94 ms\n",
      "Wall time: 910 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b28d43",
   "metadata": {},
   "source": [
    "For IVF (and IMI) indexes, before attempting to use the reconstruct method, we need to call the make_direct_map method - otherwise we will return a RunetimeError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50218e41",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in idx_t faiss::DirectMap::get(idx_t) const at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/invlists/DirectMap.cpp:83: direct map not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x0/2gdcc4dx06l26j8346nm7c5r0000gn/T/ipykernel_48751/152910070.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ai-playground/lib/python3.13/site-packages/faiss/class_wrappers.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ai-playground/lib/python3.13/site-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, recons)\u001b[0m\n\u001b[1;32m   6318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         \u001b[0;34mr\"\"\"reconstruct a vector. Works only if maintain_direct_map is set to 1 or 2\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexIVF_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in idx_t faiss::DirectMap::get(idx_t) const at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/invlists/DirectMap.cpp:83: direct map not initialized"
     ]
    }
   ],
   "source": [
    "index.reconstruct(I[0][0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d87af",
   "metadata": {},
   "source": [
    "With make_direct_map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b2371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.make_direct_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc4ad9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627056,  0.22325902, -0.15037405, -0.30747285, -0.27122435,\n",
       "       -0.1059322 , -0.06460907,  0.04738186, -0.73349047, -0.37657705,\n",
       "       -0.76762813,  0.16902864,  0.531077  ,  0.51176685,  1.1441587 ,\n",
       "       -0.08562887, -0.6724008 , -0.9663704 ,  0.02545477, -0.2155983 ,\n",
       "       -1.2565659 , -0.8298214 , -0.09825017, -0.21850841,  0.5061022 ,\n",
       "        0.10527914,  0.50396866,  0.65242904, -1.394587  ,  0.6584746 ,\n",
       "       -0.21525347, -0.22487469,  0.8181835 ,  0.08464274, -0.76141673,\n",
       "       -0.2892829 , -0.09825772, -0.73046225,  0.07855783, -0.8435462 ,\n",
       "       -0.5924206 ,  0.77471304, -1.2092053 , -0.22757967, -1.3073363 ,\n",
       "       -0.23081465, -1.3132254 ,  0.01629083, -0.97285444,  0.19308178,\n",
       "        0.47424588,  1.1892089 , -1.9674133 , -0.7006111 , -0.2963864 ,\n",
       "        0.60533714,  0.6240739 , -0.70340365, -0.86754227,  0.17673175,\n",
       "       -0.19170491, -0.02951992,  0.22623569, -0.16695412, -0.80402535,\n",
       "       -0.4591891 ,  0.69675493, -0.24928212, -1.0147871 , -0.9217456 ,\n",
       "       -0.33842635, -0.39296818, -0.8373482 , -0.11479244,  0.4604968 ,\n",
       "       -1.4521118 ,  0.6031042 ,  0.38696298, -0.04061221,  0.00453187,\n",
       "        0.24117815,  0.05396239,  0.07506445,  1.0511589 ,  0.12383952,\n",
       "       -0.712811  ,  0.11722931,  0.52238154, -0.04581202,  0.26827094,\n",
       "        0.85985345, -0.35669944, -0.64667046, -0.5435799 , -0.04310478,\n",
       "        0.9513915 , -0.15605803, -0.49625286, -0.11140249,  0.15610142],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.reconstruct(I[0][0].item())[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed310ff",
   "metadata": {},
   "source": [
    "We've now significantly reduced the search time, what can we do next?\n",
    "\n",
    "## Quantization\n",
    "Well, when storing these vectors we're storing the full (eg Flat) vector. Now in very big datasets this can quickly become a problem. Typically, we look at big datasets, and when working with large dataset we will find that storing the full vectors consumes too much space.\n",
    "\n",
    "Fortunately, FAISS comes with the ability to compress our vectors using transformations based on Product Quantization (PQ). But, what is PQ? Well, we can view it as an additional approximation step similar to our use of IVF, which allowed us to approximate by reducing the scope of our search. PQ is slightly different however, and approximates the distance (or similarity) calculation instead.\n",
    "\n",
    "PQ explanation TODO REMOVE\n",
    "\n",
    "PQ achieves this approximated distance operation by compressing the vectors themselves. This consists of a few steps.\n",
    "\n",
    "  1. We split the every original vector into several subvectors.\n",
    "\n",
    "  2. For each set of subvectors, we perform a clustering operation, creating many centroids for each subvector set.\n",
    "\n",
    "  3. In our vector of subvectors, we replace each subvector with the ID of it's nearest centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45efd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8  # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58a9ec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dcfd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7241cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9cd7f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2963  3324 14163  7295]]\n",
      "CPU times: user 552 μs, sys: 851 μs, total: 1.4 ms\n",
      "Wall time: 787 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30a445",
   "metadata": {},
   "source": [
    "Former list returned: [[7090 2963 7946 7810]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41158d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
